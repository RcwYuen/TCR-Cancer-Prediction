{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sparsemax import Sparsemax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        self.last_scores = None\n",
    "        self.last_weights = None\n",
    "\n",
    "        self.scoring_linear1 = torch.nn.Linear(768, 512)\n",
    "        self.scoring_linear2 = torch.nn.Linear(512, 128)\n",
    "        self.scoring_linear3 = torch.nn.Linear(128, 1)\n",
    "        \n",
    "        self.relu = torch.nn.ReLU(inplace = False)\n",
    "        self.sparsemax = Sparsemax(dim = 0)\n",
    "\n",
    "        self.classifying_linear1 = torch.nn.Linear(768, 512)\n",
    "        self.classifying_linear2 = torch.nn.Linear(512, 128)\n",
    "        self.classifying_linear3 = torch.nn.Linear(128, 1)\n",
    "        \n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.last_scores = self.scoring_linear3(\n",
    "            self.relu(self.scoring_linear2(\n",
    "            self.relu(self.scoring_linear1(x))\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        # There appears to be a bug with the Sparsemax function.\n",
    "        # Sparsemax only handles 2-dim tensors, therefore there is a code\n",
    "        # that does:\n",
    "        # input = input.transpose(0, self.dim)\n",
    "        # which means if I have dim = 0, no transpose will happen, therefore I\n",
    "        # need to transpose the scores first and transpose it back.\n",
    "        self.last_weights = self.sparsemax(self.last_scores.T).T\n",
    "        agg_out = torch.sum(self.last_weights * x, dim = 0, keepdim = True)\n",
    "\n",
    "        result = self.classifying_linear3(\n",
    "            self.relu(self.classifying_linear2(\n",
    "            self.relu(self.classifying_linear1(agg_out))\n",
    "            ))\n",
    "        )\n",
    "        return self.sig(result)\n",
    "\n",
    "df_pos = pd.read_parquet(\"dcr_alpha_LTX051_LN1_M13_a-LTX051_LN1_M13_b.parquet\")\n",
    "df_neg = pd.read_parquet(\"dcr_HCW_0003_6M_1_alpha.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: '--false'\n"
     ]
    }
   ],
   "source": [
    "%%script --false\n",
    "embeddings_pos = torch.from_numpy(df_pos.values).to(torch.float32)\n",
    "embeddings_neg = torch.from_numpy(df_neg.values).to(torch.float32)\n",
    "model = classifier()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "pos_trainloss = []\n",
    "neg_trainloss = []\n",
    "train_loss = []\n",
    "\n",
    "for i in tqdm(range(20)):\n",
    "    ypred = model(embeddings_pos)\n",
    "    loss_pos = criterion(torch.ones((1, 1)), ypred)\n",
    "    pos_trainloss.append(loss_pos.data.tolist())\n",
    "\n",
    "    ypred = model(embeddings_neg)\n",
    "    loss_neg = criterion(torch.zeros((1, 1)), ypred)\n",
    "    neg_trainloss.append(loss_neg.data.tolist())\n",
    "\n",
    "    loss = loss_pos + loss_neg\n",
    "    train_loss.append(loss.data.tolist())\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "plt.scatter([i for i in range(len(train_loss))], train_loss, marker = \".\", c = \"b\")\n",
    "plt.scatter([i for i in range(len(pos_trainloss))], pos_trainloss, marker = \".\", c = \"r\")\n",
    "plt.scatter([i for i in range(len(neg_trainloss))], neg_trainloss, marker = \".\", c = \"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8322334217484da8a9d929edbafecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnHklEQVR4nO3df3BU9b3/8dfuYhK1bBBSE8PGREwqpWqigaTgWB2aa/Sihbm91+j4NTFNIePFfuukzlXuraTWmRuqXi63SiHxBvHqtGJn/DG1Dl5Ng201FifBrz9hEodfW0wC9LIbwjVxdj/fP7YsLuTXhmw+OZvnY+bMsief89n34ZPDvjg/XcYYIwAAAEvctgsAAADTG2EEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFUzbBcwFuFwWIcOHdLMmTPlcrlslwMAAMbAGKO+vj5lZ2fL7R5+/4cjwsihQ4eUk5NjuwwAADAOBw8elM/nG/bnjggjM2fOlBRZGa/Xa7kaAAAwFsFgUDk5OdHv8eE4IoycPDTj9XoJIwAAOMxop1hwAisAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsGpcYWTjxo3Ky8tTWlqaSktLtXPnzmHbbt26VS6XK2ZKS0sbd8EAACC5xB1Gtm3bprq6OtXX16ujo0OFhYUqLy9Xb2/vsMt4vV599tln0Wn//v1nVTQAAEgecYeR9evXa+XKlaqurtaCBQu0efNmnXfeedqyZcuwy7hcLmVlZUWnzMzMsyoaAAAkj7jCyODgoNrb21VWVnaqA7dbZWVlamtrG3a548ePKzc3Vzk5OVq+fLk++uij8VcMAACSSlxh5MiRIwqFQmfs2cjMzFR3d/eQy1x22WXasmWLXn75ZT377LMKh8NasmSJ/H7/sJ8zMDCgYDAYMwEAgOSU8KtpFi9erMrKShUVFem6667TCy+8oK9+9atqbGwcdpmGhgalp6dHp0Q9JM/vl1pbI68AAMCOuMJIRkaGPB6Penp6Yub39PQoKytrTH2cc845uuqqq9TV1TVsmzVr1igQCESngwcPxlPmmDQ3S7m50tKlkdfm5gn/CAAAMAZxhZGUlBQVFxerpaUlOi8cDqulpUWLFy8eUx+hUEgffPCBLrroomHbpKamRh+Kl4iH4/n90qpVUjgceR8OS7W17CEBAMCGuJ/aW1dXp6qqKi1cuFAlJSXasGGD+vv7VV1dLUmqrKzU3Llz1dDQIEn66U9/qm9+85vKz8/XsWPH9Oijj2r//v36/ve/P7FrEofOzlNB5KRQSOrqknw+OzUBADBdxR1GKioqdPjwYa1du1bd3d0qKirS9u3boye1HjhwQG73qR0u//M//6OVK1equ7tbF1xwgYqLi/X2229rwYIFE7cWcSookNzu2EDi8Uj5+dZKAgBg2nIZY4ztIkYTDAaVnp6uQCAwYYdsmpsjh2ZCoUgQaWyUamompGsAAKCxf3/HvWckWdTUSOXlkUMz+fkcngEAwJZpG0akSAAhhAAAYBdP7QUAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABg1bjCyMaNG5WXl6e0tDSVlpZq586dY1ruueeek8vl0ooVK8bzsQAAIAnFHUa2bdumuro61dfXq6OjQ4WFhSovL1dvb++Iy+3bt0/33Xefrr322nEXCwAAkk/cYWT9+vVauXKlqqurtWDBAm3evFnnnXeetmzZMuwyoVBId9xxhx566CHNmzfvrAoGAADJJa4wMjg4qPb2dpWVlZ3qwO1WWVmZ2trahl3upz/9qS688ELV1NSMv1IAAJCUZsTT+MiRIwqFQsrMzIyZn5mZqd27dw+5zB//+Ec1NzfrvffeG/PnDAwMaGBgIPo+GAzGUyYAAHCQhF5N09fXpzvvvFNPPvmkMjIyxrxcQ0OD0tPTo1NOTk4CqwQAADbFtWckIyNDHo9HPT09MfN7enqUlZV1RvtPP/1U+/bt0y233BKdFw6HIx88Y4b27NmjSy+99Izl1qxZo7q6uuj7YDBIIAEAIEnFFUZSUlJUXFyslpaW6OW54XBYLS0tuueee85oP3/+fH3wwQcx83784x+rr69P//Ef/zFswEhNTVVqamo8pQEAAIeKK4xIUl1dnaqqqrRw4UKVlJRow4YN6u/vV3V1tSSpsrJSc+fOVUNDg9LS0nT55ZfHLD9r1ixJOmM+AACYnuIOIxUVFTp8+LDWrl2r7u5uFRUVafv27dGTWg8cOCC3mxu7AgCAsXEZY4ztIkYTDAaVnp6uQCAgr9druxwAADAGY/3+ZhcGAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowkkB+v9TaGnkFAABDI4wkSHOzlJsrLV0aeW1utl0RAABTE2EkAfx+adUqKRyOvA+Hpdpa9pAAADAUwkgCdHaeCiInhUJSV5edegAAmMoIIwlQUCC5T/ub9Xik/Hw79QAAMJURRhLA55OamiIBRIq8NjZG5gMAgFgzbBeQrGpqpPLyyKGZ/HyCCAAAwyGMJJDPRwgBAGA0HKYBAABWEUYAAIBVhBEAAGAVYQQAAFg1rjCyceNG5eXlKS0tTaWlpdq5c+ewbV944QUtXLhQs2bN0vnnn6+ioiI988wz4y4YAAAkl7jDyLZt21RXV6f6+np1dHSosLBQ5eXl6u3tHbL97Nmz9S//8i9qa2vT+++/r+rqalVXV+u111476+IBAIDzuYwxJp4FSktLtWjRIj3xxBOSpHA4rJycHP3gBz/QAw88MKY+rr76ai1btkwPP/zwmNoHg0Glp6crEAjI6/XGUy4AALBkrN/fce0ZGRwcVHt7u8rKyk514HarrKxMbW1toy5vjFFLS4v27Nmjb33rW/F8NAAASFJx3fTsyJEjCoVCyszMjJmfmZmp3bt3D7tcIBDQ3LlzNTAwII/Ho1/84hf6m7/5m2HbDwwMaGBgIPo+GAzGUyYAAHCQSbkD68yZM/Xee+/p+PHjamlpUV1dnebNm6frr79+yPYNDQ166KGHJqM0AABgWVxhJCMjQx6PRz09PTHze3p6lJWVNexybrdb+X99ZG1RUZE++eQTNTQ0DBtG1qxZo7q6uuj7YDConJyceEoFAAAOEdc5IykpKSouLlZLS0t0XjgcVktLixYvXjzmfsLhcMxhmNOlpqbK6/XGTAAAIDnFfZimrq5OVVVVWrhwoUpKSrRhwwb19/erurpaklRZWam5c+eqoaFBUuSQy8KFC3XppZdqYGBAr776qp555hlt2rRpYtcEAAA4UtxhpKKiQocPH9batWvV3d2toqIibd++PXpS64EDB+R2n9rh0t/fr3/8x3+U3+/Xueeeq/nz5+vZZ59VRUXFxK0FAABwrLjvM2ID9xkBAMB5EnKfEQAAgIlGGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWTe8w4vdLra2RVwAAYMX0DSPNzVJurrR0aeS1udl2RQAATEvTM4z4/dKqVVI4HHkfDku1tewhAQDAgukZRjo7TwWRk0IhqavLTj0AAExj0zOMFBRI7tNW3eOR8vPt1AMAwDQ2PcOIzyc1NUUCiBR5bWyMzAcAAJNqhu0CrKmpkcrLI4dm8vMJIgAAWDJ9w4gUCSCEEAAArJqeh2kAAMCUMa3DiD/oV+veVvmDXNILAIAt0/YwTXNHs1a9skphE5bb5VbTzU2qubrGdlkAAEw703LPiD/ojwYRSQqbsGpfqWUPCQAAFkzLMNJ5tDMaRE4KmZC6/sJNzwAAmGzTMowUzCmQ2xW76h6XR/mzuekZAACTbVqGEZ/Xp6abm+RxRW565nF51Hhzo3xeLvMFAGCyuYwxxnYRowkGg0pPT1cgEJDX652wfv1Bv7r+0qX82fkEEQAAJthYv7+n7dU0UmQPSSJDiD/oV+fRThXMKSDsAAAwjGkdRhKJS4cBABibaXnOSKJx6TAAAGNHGEkALh0GAGDsCCMJwKXDAACMHWEkAbh0GACAsZvWl/YmGpcOAwCmMy7tnQISfekwAADJgMM0AADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArBpXGNm4caPy8vKUlpam0tJS7dy5c9i2Tz75pK699lpdcMEFuuCCC1RWVjZiewAAML3EHUa2bdumuro61dfXq6OjQ4WFhSovL1dvb++Q7Xfs2KHbb79dra2tamtrU05Ojm644Qb9+c9/PuviAQCA87mMMSaeBUpLS7Vo0SI98cQTkqRwOKycnBz94Ac/0AMPPDDq8qFQSBdccIGeeOIJVVZWjukzx/oIYgAAMHWM9fs7rj0jg4ODam9vV1lZ2akO3G6VlZWpra1tTH2cOHFCX3zxhWbPnh3PRwMAgCQ1I57GR44cUSgUUmZmZsz8zMxM7d69e0x93H///crOzo4JNKcbGBjQwMBA9H0wGIynTAAA4CCTejXNunXr9Nxzz+nFF19UWlrasO0aGhqUnp4enXJyciaxSgAAMJniCiMZGRnyeDzq6emJmd/T06OsrKwRl33ssce0bt06/fd//7euvPLKEduuWbNGgUAgOh08eDCeMgEAgIPEFUZSUlJUXFyslpaW6LxwOKyWlhYtXrx42OUeeeQRPfzww9q+fbsWLlw46uekpqbK6/XGTDiT3y+1tkZeAQBwqrgP09TV1enJJ5/U008/rU8++UR33323+vv7VV1dLUmqrKzUmjVrou1/9rOf6cEHH9SWLVuUl5en7u5udXd36/jx4xO3FtNQc7OUmystXRp5bW62XREAAOMT1wmsklRRUaHDhw9r7dq16u7uVlFRkbZv3x49qfXAgQNyu09lnE2bNmlwcFB///d/H9NPfX29fvKTn5xd9dOU3y+tWiWFw5H34bBUWyuVl0s+n93aAACIV9z3GbGB+4zEam2N7BEZav711096OQAADCkh9xnB1FBQILlPGzmPR8rPt1MPAABngzDiQD6f1NQUCSBS5LWxkUM0AABnivucEUwNNTWRc0S6uiJ7RAgiAACnIow4mM9HCAEAOB+HaQAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEH8wf9at3bKn/Qb7sUAADGjdvBO1RzR7NWvbJKYROW2+VW081Nqrm6xnZZAADEjT0jDuQP+qNBRJLCJqzaV2rZQwIAcCTCiAN1Hu2MBpGTQiakrr90WaoIAIDxI4w4UMGcArldsUPncXmUPzvfUkUAAIwfYcSBfF6fmm5uksflkRQJIo03N8rn9VmuDACA+LmMMcZ2EaMJBoNKT09XIBCQ1+u1Xc6U4Q/61fWXLuXPzieIAACmnLF+f3M1jYP5vD5CCADA8ThMAwAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjGJLfL7W2Rl4BAEgkwgjO0Nws5eZKS5dGXpubbVcEAEhmhBHE8PulVaukcDjyPhyWamvZQwIASBzCCGJ0dp4KIieFQlJXl516AADJjzCCGAUFktstyeuX8lolr18ej5Sfb7syAECymmG7AEwtPp9057836+mjqyR3WAq79X/mNMnnq7FdGgAgSbFnBDH8Qb+eOfbXICJJ7rCePVYrf5CTRgAAiUEYQYzOo50Km9iTRkImpK6/cNIIACAxCCOIUTCnQG5X7K+Fx+VR/mxOGgEAJAZhBDF8Xp+abm6Sx+WRFAkijTc3yuf1Wa4MAJCsxhVGNm7cqLy8PKWlpam0tFQ7d+4ctu1HH32k7373u8rLy5PL5dKGDRvGWysmSc3VNdp37z61VrVq3737VHM1J68CABIn7jCybds21dXVqb6+Xh0dHSosLFR5ebl6e3uHbH/ixAnNmzdP69atU1ZW1lkXjMnh8/p0fd717BEBACRc3GFk/fr1Wrlypaqrq7VgwQJt3rxZ5513nrZs2TJk+0WLFunRRx/VbbfdptTU1LMuGAAAJJe4wsjg4KDa29tVVlZ2qgO3W2VlZWpra5vw4gAAQPKL66ZnR44cUSgUUmZmZsz8zMxM7d69e8KKGhgY0MDAQPR9MBicsL4BAMDUMiWvpmloaFB6enp0ysnJsV0SAABIkLjCSEZGhjwej3p6emLm9/T0TOjJqWvWrFEgEIhOBw8enLC+AQDA1BJXGElJSVFxcbFaWlqi88LhsFpaWrR48eIJKyo1NVVerzdmAgAAySnuB+XV1dWpqqpKCxcuVElJiTZs2KD+/n5VV1dLkiorKzV37lw1NDRIipz0+vHHH0f//Oc//1nvvfeevvKVryifR8ECADDtxR1GKioqdPjwYa1du1bd3d0qKirS9u3boye1HjhwQG73qR0uhw4d0lVXXRV9/9hjj+mxxx7Tddddpx07dpz9Gkxlfr/U2SkVFEQehwsAAM7gMsYY20WMJhgMKj09XYFAwDmHbJqbpVWrpHBYcrulpiaphjuZAgCmj7F+f0/Jq2kcz+8/FUSkyGttbWQ+AACIQRhJhM7OU0HkpFBI6uqyUw8AAFMYYSQRCgoih2a+zOOROGEXAIAzEEYSweeLnCPi8UTeezxSYyMnsQIAMIS4r6bBGNXUSOXlkUMz+fkEEQAAhkEYSSSfjxACAMAoOEwDAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsII7DC75daW3lcDwCAMAILmpuliy/3a+n3WnXx5X41N9uuCABgE2EEk8rvl1b+olnmh7nSXUtlfpirlZua2UMCANMYYQST6u0P/TI3r5Lcf32qsTsss6xWbR+RRgBguiKMYHLN7jwVRE5yh6TZXXbqAQBYRxjBpFoyv0Cu037t3PJo8WX5lioCANhGGMGk8nl9evKWJnlcHkmSx+VR0y2N8nl5oCAATFcuY4yxXcRogsGg0tPTFQgE5PV6bZeDCeAP+tX1ly7lz84niABAkhrr9/eMSawJiPJ5fYQQAIAkDtMAAADLCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMIKk9O4ev9a/2Kp39/htlwIAGMUM2wUAE+2unzfr6aOrJHdYes+tqjlN2vp/a2yXBQAYBntGkFTe3eM/FUQkyR3W00dr2UMCAFMYYQRJ5Q8fd54KIie5Q3rrky47BQEARkUYQVK5dkGBFD7t1zrs0TVfz7dTEABgVIQRJ/P7pdbWyCskSYsu86lqTpMU9kRmhD2qmtOoRZf57BYGABiWyxhjbBcxmmAwqPT0dAUCAXm9XtvlTA3NzdKqVVI4LLndUlOTVMNJmie9u8evtz7p0jVfzyeIAIAlY/3+Jow4kd8v5eZGgshJHo+0b5/k44sXADA1jPX7m8M0TtTZGRtEJCkUkro4SRMA4DyEEScqKIgcmvkyj0fK5yRNAIDzEEacyOeLnCPi+etJmh6P1NjIIRoAgCNxB1anqqmRyssjh2by8wkiAADHIow4mc9HCAEAOB6HaQAAgFWEEWAceCowAEwcDtMAceKpwAAwsdgzAsSBpwIDwMQjjABx4KnAADDxCCNAHHgqMABMPMIIhsYTgYfEU4EBYOLxoDyciScCjyqRTwV+d49ff/i4U9cuKCDkAHC0hD4ob+PGjcrLy1NaWppKS0u1c+fOEdv/+te/1vz585WWlqYrrrhCr7766ng+FpPB7z8VRKTIa20te0hOs+gyn+5dcf2Eh4W7ft6skl/m6kfvL1XJL3N118+bJ7R/AJiK4g4j27ZtU11dnerr69XR0aHCwkKVl5ert7d3yPZvv/22br/9dtXU1GjXrl1asWKFVqxYoQ8//PCsi0cCTNYTgRN9GMiB/U/WlTrtv39XTY+sV/vv353QfpOhfyfX7vT+nVx7ovt3cu1jZuJUUlJiVq9eHX0fCoVMdna2aWhoGLL9rbfeapYtWxYzr7S01NTW1o75MwOBgJFkAoFAvOUiXgcPGuN2GyOdmjyeyPyJ8p//eeoz3O7I+4nk0P7/7YXfGf1EZ0z//mLrhPRvjDH/tLrKuNdG+nWvlfmn1VUT1rfT+3dy7U7v38m1J7p/J9duzNi/v+PaMzI4OKj29naVlZVF57ndbpWVlamtrW3IZdra2mLaS1J5efmw7SVpYGBAwWAwZsIkSfQTgRN9GMjB/V835ytnXDXsCUvXzj7/rPuWIv/7eWzO09GLgcJu6d/mPD1h/xtycv9Ort3p/Tu59kT37+Ta4xVXGDly5IhCoZAyMzNj5mdmZqq7u3vIZbq7u+NqL0kNDQ1KT0+PTjk5OfGUibNVUyPt2xc5DLFv38SevJrow0AO7r84dFxNv4kEECny2vgbqTjcf9Z9S1L7O38446rkkFvatfOtad+/k2t3ev9Orj3R/Tu59nhNyUt716xZo0AgEJ0OHjxou6Tpx+eTrr9+4p8KXFAQuULnyzweKX+C7tPh5P4LClTz/9zat0Fq3Srt2yDVvD9xtRd/89oh97xcVXLNtO/fybU7vX8n157o/p1ce7ziCiMZGRnyeDzq6emJmd/T06OsrKwhl8nKyoqrvSSlpqbK6/XGTEgSiT4M5OT+/9q3r9+j6/dJvv6Jrb34W4t039GqmD0vPzpapeJvLZr2/Tu5dqf37+TaE92/k2uPV9z3GSktLVVJSYkef/xxSVI4HNbFF1+se+65Rw888MAZ7SsqKnTixAn95je/ic5bsmSJrrzySm3evHlMn8l9RpKQ3x85tJGfP/F7X5zef4Jrb//9u9q18y1dVXJNQv7RcXL/Tq7d6f07ufZE9+/k2sf6/R13GNm2bZuqqqrU2NiokpISbdiwQc8//7x2796tzMxMVVZWau7cuWpoaJAUubT3uuuu07p167Rs2TI999xz+td//Vd1dHTo8ssvn9CVAQAAU8dYv79nxNtxRUWFDh8+rLVr16q7u1tFRUXavn179CTVAwcOyP2lY+pLlizRL3/5S/34xz/WP//zP6ugoEAvvfTSmIMIAABIbtwOHgAAJERCbwcPAAAwUQgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKvivh28DSdvEhsMBi1XAgAAxurk9/ZoN3t3RBjp6+uTJOXk5FiuBAAAxKuvr0/p6enD/twRz6YJh8M6dOiQZs6cKZfLNWH9BoNB5eTk6ODBg9PimTfTaX1Z1+Q1ndaXdU1e02V9jTHq6+tTdnZ2zEN0T+eIPSNut1s+ny9h/Xu93qT+ZTjddFpf1jV5Taf1ZV2T13RY35H2iJzECawAAMAqwggAALBqWoeR1NRU1dfXKzU11XYpk2I6rS/rmrym0/qyrslruq3vaBxxAisAAEhe03rPCAAAsI8wAgAArCKMAAAAqwgjAADAqqQPIxs3blReXp7S0tJUWlqqnTt3jtj+17/+tebPn6+0tDRdccUVevXVVyep0rPT0NCgRYsWaebMmbrwwgu1YsUK7dmzZ8Rltm7dKpfLFTOlpaVNUsXj95Of/OSMuufPnz/iMk4d17y8vDPW1eVyafXq1UO2d9qY/v73v9ctt9yi7OxsuVwuvfTSSzE/N8Zo7dq1uuiii3TuueeqrKxMnZ2do/Yb73Y/GUZa1y+++EL333+/rrjiCp1//vnKzs5WZWWlDh06NGKf49kWJsNo43rXXXedUfeNN944ar9TcVyl0dd3qG3Y5XLp0UcfHbbPqTq2iZLUYWTbtm2qq6tTfX29Ojo6VFhYqPLycvX29g7Z/u2339btt9+umpoa7dq1SytWrNCKFSv04YcfTnLl8XvzzTe1evVqvfPOO3r99df1xRdf6IYbblB/f/+Iy3m9Xn322WfRaf/+/ZNU8dn5xje+EVP3H//4x2HbOnlc33333Zj1fP311yVJ//AP/zDsMk4a0/7+fhUWFmrjxo1D/vyRRx7Rz3/+c23evFl/+tOfdP7556u8vFyff/75sH3Gu91PlpHW9cSJE+ro6NCDDz6ojo4OvfDCC9qzZ4++853vjNpvPNvCZBltXCXpxhtvjKn7V7/61Yh9TtVxlUZf3y+v52effaYtW7bI5XLpu9/97oj9TsWxTRiTxEpKSszq1auj70OhkMnOzjYNDQ1Dtr/11lvNsmXLYuaVlpaa2trahNaZCL29vUaSefPNN4dt89RTT5n09PTJK2qC1NfXm8LCwjG3T6Zx/eEPf2guvfRSEw6Hh/y5U8fUGGMkmRdffDH6PhwOm6ysLPPoo49G5x07dsykpqaaX/3qV8P2E+92b8Pp6zqUnTt3Gklm//79w7aJd1uwYah1raqqMsuXL4+rHyeMqzFjG9vly5ebpUuXjtjGCWM7kZJ2z8jg4KDa29tVVlYWned2u1VWVqa2trYhl2lra4tpL0nl5eXDtp/KAoGAJGn27Nkjtjt+/Lhyc3OVk5Oj5cuX66OPPpqM8s5aZ2ensrOzNW/ePN1xxx06cODAsG2TZVwHBwf17LPP6nvf+96ID4x06piebu/everu7o4Zu/T0dJWWlg47duPZ7qeqQCAgl8ulWbNmjdgunm1hKtmxY4cuvPBCXXbZZbr77rt19OjRYdsm07j29PTot7/9rWpqakZt69SxHY+kDSNHjhxRKBRSZmZmzPzMzEx1d3cPuUx3d3dc7aeqcDise++9V9dcc40uv/zyYdtddtll2rJli15++WU9++yzCofDWrJkifx+/yRWG7/S0lJt3bpV27dv16ZNm7R3715de+216uvrG7J9sozrSy+9pGPHjumuu+4ato1Tx3QoJ8cnnrEbz3Y/FX3++ee6//77dfvtt4/4ELV4t4Wp4sYbb9R//dd/qaWlRT/72c/05ptv6qabblIoFBqyfbKMqyQ9/fTTmjlzpv7u7/5uxHZOHdvxcsRTexGf1atX68MPPxz1+OLixYu1ePHi6PslS5bo61//uhobG/Xwww8nusxxu+mmm6J/vvLKK1VaWqrc3Fw9//zzY/rfhlM1NzfrpptuUnZ29rBtnDqmOOWLL77QrbfeKmOMNm3aNGJbp24Lt912W/TPV1xxha688kpdeuml2rFjh7797W9brCzxtmzZojvuuGPUE8udOrbjlbR7RjIyMuTxeNTT0xMzv6enR1lZWUMuk5WVFVf7qeiee+7RK6+8otbWVvl8vriWPeecc3TVVVepq6srQdUlxqxZs/S1r31t2LqTYVz379+vN954Q9///vfjWs6pYyopOj7xjN14tvup5GQQ2b9/v15//fW4Hy0/2rYwVc2bN08ZGRnD1u30cT3pD3/4g/bs2RP3diw5d2zHKmnDSEpKioqLi9XS0hKdFw6H1dLSEvM/xy9bvHhxTHtJev3114dtP5UYY3TPPffoxRdf1O9+9ztdcsklcfcRCoX0wQcf6KKLLkpAhYlz/Phxffrpp8PW7eRxPempp57ShRdeqGXLlsW1nFPHVJIuueQSZWVlxYxdMBjUn/70p2HHbjzb/VRxMoh0dnbqjTfe0Jw5c+LuY7RtYary+/06evTosHU7eVy/rLm5WcXFxSosLIx7WaeO7ZjZPoM2kZ577jmTmppqtm7daj7++GOzatUqM2vWLNPd3W2MMebOO+80DzzwQLT9W2+9ZWbMmGEee+wx88knn5j6+npzzjnnmA8++MDWKozZ3XffbdLT082OHTvMZ599Fp1OnDgRbXP6+j700EPmtddeM59++qlpb283t912m0lLSzMfffSRjVUYsx/96Edmx44dZu/eveatt94yZWVlJiMjw/T29hpjkmtcjYlcNXDxxReb+++//4yfOX1M+/r6zK5du8yuXbuMJLN+/Xqza9eu6BUk69atM7NmzTIvv/yyef/9983y5cvNJZdcYv73f/832sfSpUvN448/Hn0/2nZvy0jrOjg4aL7zne8Yn89n3nvvvZhteGBgINrH6es62rZgy0jr2tfXZ+677z7T1tZm9u7da9544w1z9dVXm4KCAvP5559H+3DKuBoz+u+xMcYEAgFz3nnnmU2bNg3Zh1PGNlGSOowYY8zjjz9uLr74YpOSkmJKSkrMO++8E/3ZddddZ6qqqmLaP//88+ZrX/uaSUlJMd/4xjfMb3/720mueHwkDTk99dRT0Tanr++9994b/bvJzMw0f/u3f2s6Ojomv/g4VVRUmIsuusikpKSYuXPnmoqKCtPV1RX9eTKNqzHGvPbaa0aS2bNnzxk/c/qYtra2Dvl7e3KdwuGwefDBB01mZqZJTU013/72t8/4e8jNzTX19fUx80ba7m0ZaV337t077Dbc2toa7eP0dR1tW7BlpHU9ceKEueGGG8xXv/pVc84555jc3FyzcuXKM0KFU8bVmNF/j40xprGx0Zx77rnm2LFjQ/bhlLFNFJcxxiR01wsAAMAIkvacEQAA4AyEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFb9f56KbWa8GBfJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_pos = torch.from_numpy(df_pos.values).to(torch.float32).cuda()\n",
    "embeddings_neg = torch.from_numpy(df_neg.values).to(torch.float32).cuda()\n",
    "model = classifier().cuda()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "pos_trainloss = []\n",
    "neg_trainloss = []\n",
    "train_loss = []\n",
    "\n",
    "for i in tqdm(range(20)):\n",
    "    ypred = model(embeddings_pos)\n",
    "    loss_pos = criterion(torch.ones((1, 1)).cuda(), ypred)\n",
    "    pos_trainloss.append(loss_pos.data.tolist())\n",
    "\n",
    "    ypred = model(embeddings_neg)\n",
    "    loss_neg = criterion(torch.zeros((1, 1)).cuda(), ypred)\n",
    "    neg_trainloss.append(loss_neg.data.tolist())\n",
    "\n",
    "    loss = loss_pos + loss_neg\n",
    "    train_loss.append(loss.data.tolist())\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "plt.scatter([i for i in range(len(train_loss))], train_loss, marker = \".\", c = \"b\")\n",
    "plt.scatter([i for i in range(len(pos_trainloss))], pos_trainloss, marker = \".\", c = \"r\")\n",
    "plt.scatter([i for i in range(len(neg_trainloss))], neg_trainloss, marker = \".\", c = \"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.matlib import repmat\n",
    "import sys\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "sys.path.append('')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "# load in some binary test data (labels are -1, +1)\n",
    "data = loadmat(\"ion.mat\")\n",
    "xTrIon  = data['xTr'].T\n",
    "yTrIon  = data['yTr'].flatten()\n",
    "xTeIon  = data['xTe'].T\n",
    "yTeIon  = data['yTe'].flatten()\n",
    "\n",
    "class TreeNode(object):\n",
    "    \"\"\"Tree class.\n",
    "    \n",
    "    (You don't need to add any methods or fields here but feel\n",
    "    free to if you like. Our tests will only reference the fields\n",
    "    defined in the constructor below, so be sure to set these\n",
    "    correctly!)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, left, right, parent, cutoff_id, cutoff_val, prediction):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.cutoff_id = cutoff_id\n",
    "        self.cutoff_val = cutoff_val\n",
    "        self.prediction = prediction\n",
    "\n",
    "def spiraldata(N=300):\n",
    "    r = np.linspace(1,2*np.pi,N)\n",
    "    xTr1 = np.array([np.sin(2.*r)*r, np.cos(2*r)*r]).T\n",
    "    xTr2 = np.array([np.sin(2.*r+np.pi)*r, np.cos(2*r+np.pi)*r]).T\n",
    "    xTr = np.concatenate([xTr1, xTr2], axis=0)\n",
    "    yTr = np.concatenate([np.ones(N), -1 * np.ones(N)])\n",
    "    xTr = xTr + np.random.randn(xTr.shape[0], xTr.shape[1])*0.2\n",
    "    \n",
    "    xTe = xTr[::2,:]\n",
    "    yTe = yTr[::2]\n",
    "    xTr = xTr[1::2,:]\n",
    "    yTr = yTr[1::2]\n",
    "    \n",
    "    return xTr,yTr,xTe,yTe\n",
    "\n",
    "xTrSpiral,yTrSpiral,xTeSpiral,yTeSpiral=spiraldata(150)\n",
    "\n",
    "def sqsplit(xTr,yTr,weights=None):\n",
    "    \"\"\"Finds the best feature, cut value, and loss value.\n",
    "    \n",
    "    Input:\n",
    "        xTr:     n x d matrix of data points\n",
    "        yTr:     n-dimensional vector of labels\n",
    "        weights: n-dimensional weight vector for data points\n",
    "    \n",
    "    Output:\n",
    "        feature:  index of the best cut's feature\n",
    "        cut:      cut-value of the best cut\n",
    "        bestloss: loss of the best cut\n",
    "    \"\"\"\n",
    "    N,D = xTr.shape\n",
    "    assert D > 0 # must have at least one dimension\n",
    "    assert N > 1 # must have at least two samples\n",
    "    if weights is None: # if no weights are passed on, assign uniform weights\n",
    "        weights = np.ones(N)\n",
    "    weights = weights/sum(weights) # Weights need to sum to one (we just normalize them)\n",
    "    bestloss = np.inf\n",
    "    feature = np.inf\n",
    "    cut = np.inf\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in range(D):\n",
    "        xTr_idx = np.argsort(xTr[:, i])\n",
    "        xTr_sort = xTr[xTr_idx, i]\n",
    "        yTr_sort = yTr[xTr_idx]\n",
    "        ws_sorted = weights[xTr_idx]\n",
    "        \n",
    "        QRk = ws_sorted.T @ np.power(yTr_sort, 2)\n",
    "        PRk = ws_sorted.T @ yTr_sort\n",
    "        QLk, PLk, WLk = 0, 0, 0\n",
    "        WRk = 1\n",
    "\n",
    "        for j in range(N - 1):\n",
    "            # We apply the efficient update rule here.\n",
    "            WRk -= ws_sorted[j]\n",
    "            PRk -= ws_sorted[j] * yTr_sort[j]\n",
    "            QRk -= ws_sorted[j] * np.power(yTr_sort[j], 2)\n",
    "            WLk += ws_sorted[j]\n",
    "            PLk += ws_sorted[j] * yTr_sort[j]\n",
    "            QLk += ws_sorted[j] * np.power(yTr_sort[j], 2)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = (QLk - (PLk ** 2 / WLk)) + (QRk - (PRk ** 2 / WRk))\n",
    "            \n",
    "            if xTr_sort[j] != xTr_sort[j + 1] and loss < bestloss:\n",
    "                bestloss = loss\n",
    "                feature = i\n",
    "                cut = (xTr_sort[j] + xTr_sort[j + 1]) / 2\n",
    "    \n",
    "    return feature, cut, bestloss\n",
    "\n",
    "def cart(xTr,yTr,depth=np.inf,weights=None):\n",
    "    \"\"\"Builds a CART tree.\n",
    "    \n",
    "    The maximum tree depth is defined by \"maxdepth\" (maxdepth=2 means one split).\n",
    "    Each example can be weighted with \"weights\".\n",
    "\n",
    "    Args:\n",
    "        xTr:      n x d matrix of data\n",
    "        yTr:      n-dimensional vector\n",
    "        maxdepth: maximum tree depth\n",
    "        weights:  n-dimensional weight vector for data points\n",
    "\n",
    "    Returns:\n",
    "        tree: root of decision tree\n",
    "    \"\"\"\n",
    "    n,d = xTr.shape\n",
    "    if weights is None:\n",
    "        w = np.ones(n) / float(n)\n",
    "    else:\n",
    "        w = weights\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    preds = np.dot(w, yTr)\n",
    "    if depth == 1 or all(yTr == yTr[0]) or yTr.shape[0] < 2:\n",
    "        return TreeNode(*(None, ) * 5, preds)\n",
    "\n",
    "    feature, cut, bestloss = sqsplit(xTr, yTr)\n",
    "    L = np.where(xTr[:, feature] <= cut)\n",
    "    R = np.where(xTr[:, feature] > cut)\n",
    "\n",
    "    wL = w[L]\n",
    "    wR = w[R]\n",
    "    \n",
    "    carttree = TreeNode(*(None, ) * 3, feature, cut, preds)\n",
    "    \n",
    "    carttree.left = cart(\n",
    "        xTr = xTr[L], \n",
    "        yTr = yTr[L], \n",
    "        depth = depth - 1,\n",
    "        weights = wL / np.sum(wL)\n",
    "    )\n",
    "\n",
    "    carttree.right = cart(\n",
    "        xTr = xTr[R],\n",
    "        yTr = yTr[R], \n",
    "        depth = depth - 1,\n",
    "        weights = wR / np.sum(wR)\n",
    "    )\n",
    "\n",
    "    if carttree.left is not None and carttree.right is not None:\n",
    "        carttree.left.parent = carttree\n",
    "        carttree.right.parent = carttree\n",
    "    \n",
    "    return carttree\n",
    "\n",
    "\n",
    "def boosttree(x,y,maxiter=100,maxdepth=2):\n",
    "    \"\"\"Learns a boosted decision tree.\n",
    "    \n",
    "    Input:\n",
    "        x:        n x d matrix of data points\n",
    "        y:        n-dimensional vector of labels\n",
    "        maxiter:  maximum number of trees\n",
    "        maxdepth: maximum depth of a tree\n",
    "        \n",
    "    Output:\n",
    "        forest: list of TreeNode decision trees of length m\n",
    "        alphas: m-dimensional weight vector\n",
    "        \n",
    "    (note, m is at most maxiter, but may be smaller,\n",
    "    as dictated by the Adaboost algorithm)\n",
    "    \"\"\"\n",
    "    assert np.allclose(np.unique(y), np.array([-1,1])); # the labels must be -1 and 1 \n",
    "    n,d = x.shape\n",
    "    weights = np.ones(n) / n\n",
    "    preds   = None\n",
    "    forest  = []\n",
    "    alphas  = []\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    for t in range(maxiter):\n",
    "        tree = cart(x, y, maxdepth, weights)\n",
    "        ypred = evaltree(tree, x)\n",
    "        error = weights[np.sign(ypred) != y].sum()\n",
    "        if error < 0.5:\n",
    "            forest.append(tree)\n",
    "            alphas.append(0.5 * np.log((1 - error) / error))\n",
    "            weights = weights * np.exp(-alphas[-1] * y * ypred) / (2 * np.sqrt(error * (1 - error)))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return forest, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "import pandas as pd\n",
    "pd.DataFrame(a).to_csv(\"a.csv\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
