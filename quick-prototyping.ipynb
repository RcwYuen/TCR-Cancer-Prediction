{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de86e87f03b40ea84a57a39ba1a573c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m ypred \u001b[38;5;241m=\u001b[39m model(embeddings)\n\u001b[0;32m     60\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(ytrue, ypred)\n\u001b[1;32m---> 62\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     63\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     64\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sparsemax import Sparsemax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__()\n",
    "        self.last_scores = None\n",
    "        self.last_weights = None\n",
    "\n",
    "        self.scoring_linear1 = torch.nn.Linear(768, 512)\n",
    "        self.scoring_linear2 = torch.nn.Linear(512, 128)\n",
    "        self.scoring_linear3 = torch.nn.Linear(128, 1)\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sparsemax = Sparsemax(dim = 0)\n",
    "\n",
    "        self.classifying_linear1 = torch.nn.Linear(768, 512)\n",
    "        self.classifying_linear2 = torch.nn.Linear(512, 128)\n",
    "        self.classifying_linear3 = torch.nn.Linear(128, 1)\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.last_scores = self.scoring_linear3(\n",
    "            self.relu(self.scoring_linear2(\n",
    "            self.relu(self.scoring_linear1(x))\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        # There appears to be a bug with the Sparsemax function.\n",
    "        # Sparsemax only handles 2-dim tensors, therefore there is a code\n",
    "        # that does:\n",
    "        # input = input.transpose(0, self.dim)\n",
    "        # which means if I have dim = 0, no transpose will happen, therefore I\n",
    "        # need to transpose the scores first and transpose it back.\n",
    "\n",
    "        self.last_weights = self.sparsemax(self.last_scores.T).T\n",
    "        agg_out = torch.sum(self.last_weights * x, dim = 0, keepdim = True)\n",
    "        result = self.classifying_linear3(\n",
    "            self.relu(self.classifying_linear2(\n",
    "            self.relu(self.classifying_linear1(agg_out))\n",
    "            ))\n",
    "        )\n",
    "\n",
    "        return self.sig(result)\n",
    "\n",
    "df = pd.read_parquet(\"dcr_beta_LTX203_LN1_B.parquet\")\n",
    "embeddings = torch.from_numpy(df.values).to(torch.float32).cuda()\n",
    "ytrue = torch.ones((1, 1)).cuda()\n",
    "model = classifier().cuda()\n",
    "criterion = torch.nn.BCELoss()\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    ypred = model(embeddings)\n",
    "    loss = criterion(ytrue, ypred)\n",
    "\n",
    "    train_loss.append(loss.data.tolist())\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
