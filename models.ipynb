{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TPGPGVRYPL', 0.44939708709716797),\n",
       " ('GILGFVFTL', 0.1271347850561142),\n",
       " ('FPRPWLHGL', 0.07400770485401154),\n",
       " ('LLWNGPMAV', 0.035007625818252563),\n",
       " ('TPQDLNTML', 0.027008509263396263),\n",
       " ('EIYKRWII', 0.018733853474259377),\n",
       " ('HSKKKCDEL', 0.018440475687384605),\n",
       " ('TQGYFPDWQNY', 0.018129343166947365),\n",
       " ('NLVPMVATV', 0.01716885156929493),\n",
       " ('PQPELPYPQPE', 0.017030414193868637),\n",
       " ('RPRGEVRFL', 0.016987716779112816),\n",
       " ('HPVGEADYFEY', 0.015107231214642525),\n",
       " ('RFPLTFGWCF', 0.013964857906103134),\n",
       " ('other', 0.012723141349852085),\n",
       " ('RYPLTFGWCF', 0.011348765343427658),\n",
       " ('FPTKDVAL', 0.010398641228675842),\n",
       " ('EPLPQGQLTAY', 0.01029637549072504),\n",
       " ('HPKVSSEVHI', 0.009545115754008293),\n",
       " ('NFIRMVISNPAAT', 0.00897930283099413),\n",
       " ('VLEETSVML', 0.007365161087363958),\n",
       " ('FLRGRAYGL', 0.007004470098763704),\n",
       " ('VTEHDTLLY', 0.006441055331379175),\n",
       " ('QIKVRVDMV', 0.006390884984284639),\n",
       " ('LPPIVAKEI', 0.006246190518140793),\n",
       " ('FWIDLFETIG', 0.006086317822337151),\n",
       " ('KRWIILGLNK', 0.005950759630650282),\n",
       " ('IIKDYGKQM', 0.004422654863446951),\n",
       " ('KRGIVEQSSTSISSL', 0.004106194246560335),\n",
       " ('AVFDRKSDAK', 0.0039949240162968636),\n",
       " ('RYPLTFGW', 0.0031261970289051533),\n",
       " ('ATDALMTGY', 0.0031040809117257595),\n",
       " ('IVTDFSVIK', 0.003004504134878516),\n",
       " ('ELRRKMMYM', 0.0029459588695317507),\n",
       " ('ENPVVHFFKNIVTPR', 0.0028884527273476124),\n",
       " ('YLAMPFATPMEAELARRSLA', 0.0024263309314846992),\n",
       " ('FLKEKGGL', 0.0023426709230989218),\n",
       " ('KRWIIMGLNK', 0.001971757272258401),\n",
       " ('YVLDHLIVV', 0.0016790339723229408),\n",
       " ('RPHERNGFTVL', 0.0015101797180250287),\n",
       " ('ISPRTL-W', 0.001482986262999475),\n",
       " ('KAFSPEVIPMF', 0.0014301413903012872),\n",
       " ('RAKFKQLL', 0.0008237476577050984),\n",
       " ('QIKVRVKMV', 0.0007675427477806807),\n",
       " ('TPRVTGGGAM', 0.000731086649466306),\n",
       " ('GLCTLVAML', 0.00034698128001764417)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "class_labels = {\n",
    "    0: \"LLWNGPMAV\",\n",
    "    1: \"RPRGEVRFL\",\n",
    "    2: \"ATDALMTGY\",\n",
    "    3: \"HSKKKCDEL\",\n",
    "    4: \"KAFSPEVIPMF\",\n",
    "    5: \"KRWIILGLNK\",\n",
    "    6: \"KRWIIMGLNK\",\n",
    "    7: \"TPQDLNTML\",\n",
    "    8: \"EIYKRWII\",\n",
    "    9: \"ISPRTL-W\",\n",
    "    10: \"FLKEKGGL\",\n",
    "    11: \"HPKVSSEVHI\",\n",
    "    12: \"IIKDYGKQM\",\n",
    "    13: \"LPPIVAKEI\",\n",
    "    14: \"RFPLTFGWCF\",\n",
    "    15: \"RYPLTFGWCF\",\n",
    "    16: \"TPGPGVRYPL\",\n",
    "    17: \"TQGYFPDWQNY\",\n",
    "    18: \"FPRPWLHGL\",\n",
    "    19: \"RYPLTFGW\",\n",
    "    20: \"ELRRKMMYM\",\n",
    "    21: \"QIKVRVDMV\",\n",
    "    22: \"QIKVRVKMV\",\n",
    "    23: \"VLEETSVML\",\n",
    "    24: \"FPTKDVAL\",\n",
    "    25: \"NLVPMVATV\",\n",
    "    26: \"RPHERNGFTVL\",\n",
    "    27: \"TPRVTGGGAM\",\n",
    "    28: \"VTEHDTLLY\",\n",
    "    29: \"YLAMPFATPMEAELARRSLA\",\n",
    "    30: \"GLCTLVAML\",\n",
    "    31: \"YVLDHLIVV\",\n",
    "    32: \"EPLPQGQLTAY\",\n",
    "    33: \"RAKFKQLL\",\n",
    "    34: \"HPVGEADYFEY\",\n",
    "    35: \"FLRGRAYGL\",\n",
    "    36: \"AVFDRKSDAK\",\n",
    "    37: \"IVTDFSVIK\",\n",
    "    38: \"NFIRMVISNPAAT\",\n",
    "    39: \"KRGIVEQSSTSISSL\",\n",
    "    40: \"ENPVVHFFKNIVTPR\",\n",
    "    41: \"GILGFVFTL\",\n",
    "    42: \"PQPELPYPQPE\",\n",
    "    43: \"FWIDLFETIG\",\n",
    "    44: \"other\"\n",
    "  }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"wukevin/tcr-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"wukevin/tcr-bert\")\n",
    "\n",
    "input_text = \"I like you. I love you\".upper()\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "logits = outputs.logits\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "\n",
    "result = list(zip(list(class_labels.values()), probabilities.tolist()[0]))\n",
    "result.sort(key = lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted word: F, Probability: 0.9051\n",
      "Predicted word: T, Probability: 0.0153\n",
      "Predicted word: L, Probability: 0.0133\n",
      "Predicted word: Y, Probability: 0.0123\n",
      "Predicted word: Q, Probability: 0.0059\n"
     ]
    }
   ],
   "source": [
    "class_labels = {0: \"R\", 1: \"H\", 2: \"K\", 3: \"D\", 4: \"E\", 5: \"S\", 6: \"T\", 7: \"N\", 8: \"Q\", 9: \"C\", 10: \"U\", 11: \"G\", 12: \"P\", 13: \"A\", 14: \"V\", 15: \"I\", 16: \"L\", 17: \"M\", 18: \"F\", 19: \"Y\", 20: \"W\", 21: \"$\", 22: \".\", 23: \"?\", 24: \"|\", 25: \"*\"}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/mlm-only/tokenizer\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"model/mlm-only/model\")\n",
    "\n",
    "input_text = \"Paris is the [MASK] of France.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "predictions = outputs.logits\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = predictions[0, mask_token_index, :]\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "token_probabilities = torch.softmax(mask_token_logits, dim=1)\n",
    "\n",
    "# Get the top 5 predicted tokens and their probabilities\n",
    "top_5_tokens = torch.topk(token_probabilities, 5, dim=1)\n",
    "top_5_token_ids = top_5_tokens.indices[0].tolist()\n",
    "top_5_probabilities = top_5_tokens.values[0].tolist()\n",
    "\n",
    "# Convert predicted token IDs to words and print them with probabilities\n",
    "for token_id, probability in zip(top_5_token_ids, top_5_probabilities):\n",
    "    word = tokenizer.decode([token_id])\n",
    "    print(f\"Predicted word: {word}, Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
