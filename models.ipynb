{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y = \"TPGPGVRYPL\"              | x = x) = 0.44940\n",
      "P(Y = \"GILGFVFTL\"               | x = x) = 0.12713\n",
      "P(Y = \"FPRPWLHGL\"               | x = x) = 0.07401\n",
      "P(Y = \"LLWNGPMAV\"               | x = x) = 0.03501\n",
      "P(Y = \"TPQDLNTML\"               | x = x) = 0.02701\n",
      "P(Y = \"EIYKRWII\"                | x = x) = 0.01873\n",
      "P(Y = \"HSKKKCDEL\"               | x = x) = 0.01844\n",
      "P(Y = \"TQGYFPDWQNY\"             | x = x) = 0.01813\n",
      "P(Y = \"NLVPMVATV\"               | x = x) = 0.01717\n",
      "P(Y = \"PQPELPYPQPE\"             | x = x) = 0.01703\n",
      "P(Y = \"RPRGEVRFL\"               | x = x) = 0.01699\n",
      "P(Y = \"HPVGEADYFEY\"             | x = x) = 0.01511\n",
      "P(Y = \"RFPLTFGWCF\"              | x = x) = 0.01396\n",
      "P(Y = \"other\"                   | x = x) = 0.01272\n",
      "P(Y = \"RYPLTFGWCF\"              | x = x) = 0.01135\n",
      "P(Y = \"FPTKDVAL\"                | x = x) = 0.01040\n",
      "P(Y = \"EPLPQGQLTAY\"             | x = x) = 0.01030\n",
      "P(Y = \"HPKVSSEVHI\"              | x = x) = 0.00955\n",
      "P(Y = \"NFIRMVISNPAAT\"           | x = x) = 0.00898\n",
      "P(Y = \"VLEETSVML\"               | x = x) = 0.00737\n",
      "P(Y = \"FLRGRAYGL\"               | x = x) = 0.00700\n",
      "P(Y = \"VTEHDTLLY\"               | x = x) = 0.00644\n",
      "P(Y = \"QIKVRVDMV\"               | x = x) = 0.00639\n",
      "P(Y = \"LPPIVAKEI\"               | x = x) = 0.00625\n",
      "P(Y = \"FWIDLFETIG\"              | x = x) = 0.00609\n",
      "P(Y = \"KRWIILGLNK\"              | x = x) = 0.00595\n",
      "P(Y = \"IIKDYGKQM\"               | x = x) = 0.00442\n",
      "P(Y = \"KRGIVEQSSTSISSL\"         | x = x) = 0.00411\n",
      "P(Y = \"AVFDRKSDAK\"              | x = x) = 0.00399\n",
      "P(Y = \"RYPLTFGW\"                | x = x) = 0.00313\n",
      "P(Y = \"ATDALMTGY\"               | x = x) = 0.00310\n",
      "P(Y = \"IVTDFSVIK\"               | x = x) = 0.00300\n",
      "P(Y = \"ELRRKMMYM\"               | x = x) = 0.00295\n",
      "P(Y = \"ENPVVHFFKNIVTPR\"         | x = x) = 0.00289\n",
      "P(Y = \"YLAMPFATPMEAELARRSLA\"    | x = x) = 0.00243\n",
      "P(Y = \"FLKEKGGL\"                | x = x) = 0.00234\n",
      "P(Y = \"KRWIIMGLNK\"              | x = x) = 0.00197\n",
      "P(Y = \"YVLDHLIVV\"               | x = x) = 0.00168\n",
      "P(Y = \"RPHERNGFTVL\"             | x = x) = 0.00151\n",
      "P(Y = \"ISPRTL-W\"                | x = x) = 0.00148\n",
      "P(Y = \"KAFSPEVIPMF\"             | x = x) = 0.00143\n",
      "P(Y = \"RAKFKQLL\"                | x = x) = 0.00082\n",
      "P(Y = \"QIKVRVKMV\"               | x = x) = 0.00077\n",
      "P(Y = \"TPRVTGGGAM\"              | x = x) = 0.00073\n",
      "P(Y = \"GLCTLVAML\"               | x = x) = 0.00035\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "class_labels = {\n",
    "    0: \"LLWNGPMAV\",\n",
    "    1: \"RPRGEVRFL\",\n",
    "    2: \"ATDALMTGY\",\n",
    "    3: \"HSKKKCDEL\",\n",
    "    4: \"KAFSPEVIPMF\",\n",
    "    5: \"KRWIILGLNK\",\n",
    "    6: \"KRWIIMGLNK\",\n",
    "    7: \"TPQDLNTML\",\n",
    "    8: \"EIYKRWII\",\n",
    "    9: \"ISPRTL-W\",\n",
    "    10: \"FLKEKGGL\",\n",
    "    11: \"HPKVSSEVHI\",\n",
    "    12: \"IIKDYGKQM\",\n",
    "    13: \"LPPIVAKEI\",\n",
    "    14: \"RFPLTFGWCF\",\n",
    "    15: \"RYPLTFGWCF\",\n",
    "    16: \"TPGPGVRYPL\",\n",
    "    17: \"TQGYFPDWQNY\",\n",
    "    18: \"FPRPWLHGL\",\n",
    "    19: \"RYPLTFGW\",\n",
    "    20: \"ELRRKMMYM\",\n",
    "    21: \"QIKVRVDMV\",\n",
    "    22: \"QIKVRVKMV\",\n",
    "    23: \"VLEETSVML\",\n",
    "    24: \"FPTKDVAL\",\n",
    "    25: \"NLVPMVATV\",\n",
    "    26: \"RPHERNGFTVL\",\n",
    "    27: \"TPRVTGGGAM\",\n",
    "    28: \"VTEHDTLLY\",\n",
    "    29: \"YLAMPFATPMEAELARRSLA\",\n",
    "    30: \"GLCTLVAML\",\n",
    "    31: \"YVLDHLIVV\",\n",
    "    32: \"EPLPQGQLTAY\",\n",
    "    33: \"RAKFKQLL\",\n",
    "    34: \"HPVGEADYFEY\",\n",
    "    35: \"FLRGRAYGL\",\n",
    "    36: \"AVFDRKSDAK\",\n",
    "    37: \"IVTDFSVIK\",\n",
    "    38: \"NFIRMVISNPAAT\",\n",
    "    39: \"KRGIVEQSSTSISSL\",\n",
    "    40: \"ENPVVHFFKNIVTPR\",\n",
    "    41: \"GILGFVFTL\",\n",
    "    42: \"PQPELPYPQPE\",\n",
    "    43: \"FWIDLFETIG\",\n",
    "    44: \"other\"\n",
    "  }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"wukevin/tcr-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"wukevin/tcr-bert\")\n",
    "\n",
    "input_text = \"I like you. I love you\".upper()\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "logits = outputs.logits\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "\n",
    "result = list(zip(list(class_labels.values()), probabilities.tolist()[0]))\n",
    "result.sort(key = lambda x: -x[1])\n",
    "for word, probability in result:\n",
    "    word = '\\\"' + word + '\\\"'\n",
    "    print(f\"P(Y = {word:25} | x = x) = {probability:.5f}\")\n",
    "    # print(f\"Class: {word:30}| Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted word: S, Probability: 0.9094\n",
      "Predicted word: G, Probability: 0.0593\n",
      "Predicted word: R, Probability: 0.0181\n",
      "Predicted word: W, Probability: 0.0024\n",
      "Predicted word: I, Probability: 0.0021\n"
     ]
    }
   ],
   "source": [
    "class_labels = {0: \"R\", 1: \"H\", 2: \"K\", 3: \"D\", 4: \"E\", 5: \"S\", 6: \"T\", 7: \"N\", 8: \"Q\", 9: \"C\", 10: \"U\", 11: \"G\", 12: \"P\", 13: \"A\", 14: \"V\", 15: \"I\", 16: \"L\", 17: \"M\", 18: \"F\", 19: \"Y\", 20: \"W\", 21: \"$\", 22: \".\", 23: \"?\", 24: \"|\", 25: \"*\"}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/mlm-only/tokenizer\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"./model/mlm-only/model\")\n",
    "\n",
    "input_text = \" \".join(list(\"CALSDVEGAQKL.F\")) # V\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "predictions = outputs.logits\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = predictions[0, mask_token_index, :]\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "token_probabilities = torch.softmax(mask_token_logits, dim=1)\n",
    "\n",
    "# Get the top 5 predicted tokens and their probabilities\n",
    "top_5_tokens = torch.topk(token_probabilities, 5, dim=1)\n",
    "top_5_token_ids = top_5_tokens.indices[0].tolist()\n",
    "top_5_probabilities = top_5_tokens.values[0].tolist()\n",
    "\n",
    "# Convert predicted token IDs to words and print them with probabilities\n",
    "for token_id, probability in zip(top_5_token_ids, top_5_probabilities):\n",
    "    word = tokenizer.decode([token_id])\n",
    "    print(f\"Predicted word: {word}, Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(26, 768, padding_idx=21)\n",
       "    (position_embeddings): Embedding(64, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert(**inputs).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 26])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**inputs).logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
