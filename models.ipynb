{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "class_labels = {\n",
    "    0: \"LLWNGPMAV\",\n",
    "    1: \"RPRGEVRFL\",\n",
    "    2: \"ATDALMTGY\",\n",
    "    3: \"HSKKKCDEL\",\n",
    "    4: \"KAFSPEVIPMF\",\n",
    "    5: \"KRWIILGLNK\",\n",
    "    6: \"KRWIIMGLNK\",\n",
    "    7: \"TPQDLNTML\",\n",
    "    8: \"EIYKRWII\",\n",
    "    9: \"ISPRTL-W\",\n",
    "    10: \"FLKEKGGL\",\n",
    "    11: \"HPKVSSEVHI\",\n",
    "    12: \"IIKDYGKQM\",\n",
    "    13: \"LPPIVAKEI\",\n",
    "    14: \"RFPLTFGWCF\",\n",
    "    15: \"RYPLTFGWCF\",\n",
    "    16: \"TPGPGVRYPL\",\n",
    "    17: \"TQGYFPDWQNY\",\n",
    "    18: \"FPRPWLHGL\",\n",
    "    19: \"RYPLTFGW\",\n",
    "    20: \"ELRRKMMYM\",\n",
    "    21: \"QIKVRVDMV\",\n",
    "    22: \"QIKVRVKMV\",\n",
    "    23: \"VLEETSVML\",\n",
    "    24: \"FPTKDVAL\",\n",
    "    25: \"NLVPMVATV\",\n",
    "    26: \"RPHERNGFTVL\",\n",
    "    27: \"TPRVTGGGAM\",\n",
    "    28: \"VTEHDTLLY\",\n",
    "    29: \"YLAMPFATPMEAELARRSLA\",\n",
    "    30: \"GLCTLVAML\",\n",
    "    31: \"YVLDHLIVV\",\n",
    "    32: \"EPLPQGQLTAY\",\n",
    "    33: \"RAKFKQLL\",\n",
    "    34: \"HPVGEADYFEY\",\n",
    "    35: \"FLRGRAYGL\",\n",
    "    36: \"AVFDRKSDAK\",\n",
    "    37: \"IVTDFSVIK\",\n",
    "    38: \"NFIRMVISNPAAT\",\n",
    "    39: \"KRGIVEQSSTSISSL\",\n",
    "    40: \"ENPVVHFFKNIVTPR\",\n",
    "    41: \"GILGFVFTL\",\n",
    "    42: \"PQPELPYPQPE\",\n",
    "    43: \"FWIDLFETIG\",\n",
    "    44: \"other\"\n",
    "  }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"wukevin/tcr-bert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"wukevin/tcr-bert\")\n",
    "\n",
    "input_text = \"I like you. I love you\".upper()\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "logits = outputs.logits\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "\n",
    "\n",
    "result = list(zip(list(class_labels.values()), probabilities.tolist()[0]))\n",
    "result.sort(key = lambda x: -x[1])\n",
    "for word, probability in result:\n",
    "    word = '\\\"' + word + '\\\"'\n",
    "    print(f\"P(Y = {word:25} | x = x) = {probability:.5f}\")\n",
    "    # print(f\"Class: {word:30}| Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "class_labels = {0: \"R\", 1: \"H\", 2: \"K\", 3: \"D\", 4: \"E\", 5: \"S\", 6: \"T\", 7: \"N\", 8: \"Q\", 9: \"C\", 10: \"U\", 11: \"G\", 12: \"P\", 13: \"A\", 14: \"V\", 15: \"I\", 16: \"L\", 17: \"M\", 18: \"F\", 19: \"Y\", 20: \"W\", 21: \"$\", 22: \".\", 23: \"?\", 24: \"|\", 25: \"*\"}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./model/mlm-only/tokenizer\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"./model/mlm-only/model\").bert\n",
    "text = [\"CATVSFTGANSKLTF\", \"CADNDYKLSF\"]\n",
    "\n",
    "input_text = [\" \".join(list(\".\" + i[1::])) for i in text]\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding = True)\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    \n",
    "embeddings = outputs.last_hidden_state[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(embeddings.tolist()).to_parquet(\"file.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"file.parquet\").to_csv(\"file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = outputs.logits\n",
    "mask_token_index = torch.where(inputs.input_ids == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = predictions[0, mask_token_index, :]\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "token_probabilities = torch.softmax(mask_token_logits, dim=1)\n",
    "\n",
    "# Get the top 5 predicted tokens and their probabilities\n",
    "top_5_tokens = torch.topk(token_probabilities, 5, dim=1)\n",
    "top_5_token_ids = top_5_tokens.indices[0].tolist()\n",
    "top_5_probabilities = top_5_tokens.values[0].tolist()\n",
    "\n",
    "# Convert predicted token IDs to words and print them with probabilities\n",
    "for token_id, probability in zip(top_5_token_ids, top_5_probabilities):\n",
    "    word = tokenizer.decode([token_id])\n",
    "    print(f\"Predicted word: {word}, Probability: {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.path.exists(Path(\"C:\\\\Users\\\\rcwyuen\\OneDrive - University College London\\\\Academic\\\\Year 4 2023-2024\\\\Y4 COMP0138 Dissertation\\\\Code\\\\TCR-Cancer-Prediction\\\\data\\\\embeddings\\\\lung_cancer\\\\f.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embeddings'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path(\"C:\\\\Users\\\\rcwyuen\\OneDrive - University College London\\\\Academic\\\\Year 4 2023-2024\\\\Y4 COMP0138 Dissertation\\\\Code\\\\TCR-Cancer-Prediction\\\\data\\\\embeddings\\\\lung_cancer.csv\")\n",
    "p.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcr-cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
