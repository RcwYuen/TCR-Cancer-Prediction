# Multi-Instance Transfer Learning on TCR LLMs for Cancer Prediction

This project aims to investigate difference between the expressivity of physico-chemical properties (i.e. Atchley factors) and language models in cancer classifications using TCR CDR3 sequences.  With the use of a language model, we obtained high AUCs in classifying whether a patient has cancer.

For more details regarding this research, please view my dissertation [here](manuscript.pdf).

---

## Installation

1. Download this repository
2. Create a Python Environment venv through
   ``python3 -m venv $YOUR-VENV-NAME-HERE$``
3. Activate your virtual environment, and run the following command
   ``python -m pip install -r scripts/requirements.txt``
   if your computer is a Windows Computer, and 
   ``python -m pip install -r scripts/requirements-linux.txt``
   if it is Linux Ubuntu instead.

> [!NOTE]
> You should install your own version of PyTorch depending on your CUDA version before installing the `requirements.txt`.  You may find instructions of installing PyTorch [here](https://pytorch.org/).

> [!NOTE]
> SCEPTR is closed source as of this current moment.  Please contact [this email](mailto://rcwyuen@gmail.com) for more details.

---

## Downloading Required Files

> [!IMPORTANT]
> To download the data, you would need to have access to the Chain Lab RDS and be connected with UCL's network.

### Data Fetching

To pull the data from the Chain Lab RDS, you may run the following command.

```
python loaders/load_cdr.py -config_path loaders/config.json
```

Please modify ``rds_mountpoint`` in ``loaders/config.json`` to your mountpoint in your computer.  You should not amend other configurations in the file.

To compress the data (i.e. removing all data other than V call, J call and CDR3 sequences), you may run

```
python utils/file-compressor.py
```

### Downloading TCR-BERT

To download the two variants of [TCR-BERT](https://www.biorxiv.org/content/10.1101/2021.11.18.469186v1), you may run the following command:

```
python loaders/load_ptm.py -o model
```

### Downloading SCEPTR

Please refer to SCEPTR's repository for downloading instructions

---

## Usage

The training script takes in a configuration file, which can be generated by:
``python trainer.py --make``
This will continue the execution with the default configurations.  If you want it to end after generating the script you may run:
``python trainer.py --make --end``

### Training Configurations

To modify the training configurations, you may modify the config.json as generated.  The configurations for the 3 training scripts are different.  You may find the description for each field in each training script as below:

| Encoding Method  | Configurations Description                           |
| ---------------- | ---------------------------------------------------- |
| SCEPTR           | [Descriptions Here](instructions/sceptr-config.md)   |
| TCR-BERT         | [Descriptions Here](instructions/tcrbert-config.md)  |
| Symbolic         | [Descriptions Here](instructions/symbolic-config.md) |


### Post-Training Files & Checkpoints

Throughout training, checkpoints will be made alongside with this current epoch's training statistics such as loss, accuracies and sufficient data to compute the AUC.  This repository provides Jupyter Files to analyse the whole training loop's statistics.  The Jupyter Files are as follows:

#### `training-stats-analysis.ipynb`

#### `training-stats-combined.ipynb`

#### `sceptr-similarity.ipynb`

#### `sceptr-interpretability.ipynb`

#### `eval-stats-combined.ipynb`

## Known Errors

- Path Length Problems: If your path is too long in Windows, you are prone to the following error:

  ``DLL load failed while importing $SOMETHING$: The filename or extension is too long.``

  A mitigation strategy is to use the global Python, or to put your files in a shorter directory.
